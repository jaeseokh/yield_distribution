---
title: "2.1_mbme_tack_2012"
author: "Jaeseok Hwang"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
  word_document: defaulta
---
```{r library, cache = F, echo = F, results = "hide"}

library(haven)
library(dplyr)
library(tidyr)
library(stringr)
library(data.table)
library(fixest)

```


## Data Cleaning

```{r data clean from Stata to R, cache = F, echo = F, results = "hide"}
# Step corresponds to CleanData.do (Stata) section - creating CleanData.dta
# Matches Table 1 Summary Stats in Tack (2012)
# Load and combine AR, MS, TX yield data

# ---------------------------
# [CleanData.do] global dr = rawdata folder
# ---------------------------

teck_dir <- "/Users/jaeseokhwang/dist_yield/Data/Teck_2012" 
out_dir <- "/Users/jaeseokhwang/dist_yield/Data/Teck_2012/Rconv"


# ---------------------------
# [CleanData.do] use AR.dta; append MS; append TX
# ---------------------------

# Load and combine state-level data
ar <- read_dta(file.path(teck_dir,"/rawdata","UpCotton_AR.dta"))
ms <- read_dta(file.path(teck_dir,"/rawdata", "UpCotton_MS.dta"))
tx <- read_dta(file.path(teck_dir,"/rawdata", "UpCotton_TX.dta"))

df_bind <- bind_rows(ar, ms, tx)


# ---------------------------
# [CleanData.do] drop if County_Code == 998
# gen Id = 1000*State_Fips + County_Code
# rename State_Fips St
#  keep only planted & production items for IRRIGATED and NON-IRRIGATED
# replace names for clarity (IrrPlan, IrrProd, etc.)
# reshape wide Value, i(Year Id St) j(Data_Item) string
# gen YieldIrr = ValueIrrProd/ValueIrrPlan; same for Nir
# rename Plan vars; drop production vars
# reshape long Yield Plan, i(Year Id St) j(Prac) string
# generate Trend, Trend2, irrigation dummy dIr, Fweight = int(Plan)
# drop d2 Prac Plan
# drop if Yield == ., keep only counties with >= 34 years
# create Yield1, Yield2, Yield3 for the moment estimation
# create state dummies tab St, gen(St)
# merge with historical weather.dta
# merge with shifted weather WeatherShift.dta
# sort Id Year; order Id Year Yield1 Yield2 Yield3
# ---------------------------


# Filter and clean
df_bind <- df_bind %>%
  filter(County_Code != 998) %>%
  mutate(
    Id = 1000 * State_Fips + County_Code,
    St = State_Fips
  ) %>%
  dplyr::select(Year, Id, St, Data_Item, Value) %>%
  filter(Year >= 1972 & Year <= 2005) %>%
  filter(Data_Item %in% c(
    "COTTON, UPLAND, IRRIGATED - ACRES PLANTED",
    "COTTON, UPLAND, IRRIGATED - PRODUCTION, MEASURED IN 480 LB BALES",
    "COTTON, UPLAND, NON-IRRIGATED - ACRES PLANTED",
    "COTTON, UPLAND, NON-IRRIGATED - PRODUCTION, MEASURED IN 480 LB BALES"
  )) %>%
  mutate(Data_Item = recode(Data_Item,
    "COTTON, UPLAND, IRRIGATED - ACRES PLANTED" = "IrrPlan",
    "COTTON, UPLAND, IRRIGATED - PRODUCTION, MEASURED IN 480 LB BALES" = "IrrProd",
    "COTTON, UPLAND, NON-IRRIGATED - ACRES PLANTED" = "NirPlan",
    "COTTON, UPLAND, NON-IRRIGATED - PRODUCTION, MEASURED IN 480 LB BALES" = "NirProd"
  )) %>%
  pivot_wider(names_from = Data_Item, values_from = Value) %>%
  mutate(
    YieldIrr = IrrProd / IrrPlan,
    YieldNir = NirProd / NirPlan,
    PlanIrr = IrrPlan,
    PlanNir = NirPlan
  ) %>%
  dplyr::select(-IrrProd, -NirProd) %>%
  pivot_longer(cols = starts_with("Yield"), names_to = "Prac", values_to = "Yield") %>%
  mutate(
    Plan = ifelse(Prac == "YieldIrr", PlanIrr, PlanNir),
    dIr = ifelse(Prac == "YieldIrr", 1, 0),
    Trend = Year - 1971,
    Trend2 = (Year - 1971)^2,
    Fweight = as.integer(Plan)
  ) %>%
  filter(!is.na(Yield)) %>%
  group_by(Id, dIr) %>%
  filter(n() >= 34) %>%
  ungroup() %>%
  mutate(
    Yield1 = Yield,
    Yield2 = Yield^2,
    Yield3 = Yield^3
  ) %>%
  dplyr::select(-Prac, -Plan)

# Add state dummy variables
df_bind <- df_bind %>%
  mutate(across(St, as.integer)) %>%
  mutate(St5 = as.integer(St == 5), St28 = as.integer(St == 28), St48 = as.integer(St == 48))

# Merge with weather data
weather <- read_dta(file.path(teck_dir,"/rawdata", "weather.dta"))
df_comp <- left_join(df_bind, weather, by = c("Id", "Year")) %>%
  filter(!is.na(dday0_14C)) %>%
  mutate(precsq = prec^2)

weather_shift <- read_dta(file.path(teck_dir,"/rawdata", "WeatherShift.dta"))
df_fin <- left_join(df_comp, weather_shift, by = c("Id", "Year")) %>%
  filter(!is.na(dday0_14C))

# Sort and save final data
df_fin <- df_fin %>% arrange(Id, Year)


# Recode state names
df_fin <- df_fin %>%
  mutate(
    State = case_when(
      St == 5 ~ "Arkansas",
      St == 28 ~ "Mississippi",
      St == 48 ~ "Texas",
      TRUE ~ "Other"
    )
  )

# Generate the summary table
table1_summary <- df_fin %>%
  filter(State %in% c("Arkansas", "Mississippi", "Texas")) %>%
  group_by(State) %>%
  summarise(
    n_obs = n(),
    Mean_Yield = mean(Yield1, na.rm = TRUE),
    SD_Yield = sd(Yield1, na.rm = TRUE),
    Min_Yield = min(Yield1, na.rm = TRUE),
    Max_Yield = max(Yield1, na.rm = TRUE),

    Mean_LowTemp = mean(dday0_14C, na.rm = TRUE),
    SD_LowTemp = sd(dday0_14C, na.rm = TRUE),

    Mean_MidTemp = mean(dday15_31C, na.rm = TRUE),
    SD_MidTemp = sd(dday15_31C, na.rm = TRUE),

    Mean_HighTemp = mean(dday32_maxC, na.rm = TRUE),
    SD_HighTemp = sd(dday32_maxC, na.rm = TRUE),

    Mean_Prec = mean(prec, na.rm = TRUE),
    SD_Prec = sd(prec, na.rm = TRUE),

    Mean_Irrig = mean(dIr, na.rm = TRUE),
    SD_Irrig = sd(dIr, na.rm = TRUE)
  ) %>%
  arrange(State)

# Show the result
table1_summary

# Save to RDS (or use write.csv if needed)
saveRDS(df_fin, file = file.path(out_dir, "CleanData.Rds"))




```


# Estimate Moment and Maxmimum Entropy

```{r moment estimate check , cache = F, echo = F, results = "hide"}
# Matches Step 2 of Tack (2012) methodology: regress yield, yield^2, yield^3 separately
# Matches equations (1)-(3) in Tack (2012) for first three conditional moments
# Subset Arkansas (St = 5)

# Subset to Arkansas
df_ar <- df_fin %>% filter(St == 5)


# Moment Regressions
model_y1 <- feols(Yield1 ~ dday0_14C + dday15_31C + dday32_maxC +
                  prec + I(prec^2) + dIr + dIr:prec + dIr:I(prec^2) +
                  Trend + Trend2 + factor(Id) + factor(Id):dIr,
                  data = df_ar, weights = ~Fweight, cluster = ~Year)

model_y2 <- update(model_y1, Yield2 ~ .)
model_y3 <- update(model_y1, Yield3 ~ .)


# Summary with clustered SEs
etable(model_y1, model_y2, model_y3,
       se = "cluster", cluster = ~Year,
       dict = c(
         dday0_14C = "Low Temp",
         dday15_31C = "Mid Temp",
         dday32_maxC = "High Temp",
         prec = "Precipitation",
         `I(prec^2)` = "Precip²",
         dIr = "Irrigation",
         `dIr:prec` = "Irr × Precip",
         `dIr:I(prec^2)` = "Irr × Precip²",
         Trend = "Trend", Trend2 = "Trend²"
       ),
       fitstat = ~n + r2)

```


```{r moment and MBME , cache = F, echo = F, results = "hide"}
# Matches Step 3 of Tack (2012) methodology: predict moments under four scenarios
# Matches Table 3 and Table 4 for scenario definitions (dry_base, dry_shift, irr_base, irr_shift)
# Define prediction function to output first three conditional moments per scenario


## 2. Functions for Moment Estimation and Maximum Entropy

# Predict conditional moments for a county under a scenario
predict_moments_for_county <- function(df, model_y1, model_y2, model_y3, county_id) {
  county_data <- df %>% filter(Id == county_id)
  
  avg_climate <- county_data %>%
    summarise(across(c(dday0_14C, dday15_31C, dday32_maxC, prec), ~mean(.x, na.rm = TRUE))) %>%
    mutate(precsq = prec^2)
  
  # Shifted climate: +1 degree C to each temperature variable
  shifted_climate <- avg_climate %>%
    mutate(
      dday0_14C = dday0_14C,
      dday15_31C = dday15_31C,
      dday32_maxC = dday32_maxC + 1,  # Only shift high temperature!
      precsq = prec^2
    )
  
  # Build four scenarios
  scenarios <- list(
    dry_base = data.frame(
      dIr = 0, prec = avg_climate$prec, `I(prec^2)` = avg_climate$precsq,
      dday0_14C = avg_climate$dday0_14C, dday15_31C = avg_climate$dday15_31C,
      dday32_maxC = avg_climate$dday32_maxC, Trend = 0, Trend2 = 0, Id = as.factor(county_id)
    ),
    dry_shift = data.frame(
      dIr = 0, prec = shifted_climate$prec, `I(prec^2)` = shifted_climate$precsq,
      dday0_14C = shifted_climate$dday0_14C, dday15_31C = shifted_climate$dday15_31C,
      dday32_maxC = shifted_climate$dday32_maxC, Trend = 0, Trend2 = 0, Id = as.factor(county_id)
    ),
    irr_base = data.frame(
      dIr = 1, prec = avg_climate$prec, `I(prec^2)` = avg_climate$precsq,
      dday0_14C = avg_climate$dday0_14C, dday15_31C = avg_climate$dday15_31C,
      dday32_maxC = avg_climate$dday32_maxC, Trend = 0, Trend2 = 0, Id = as.factor(county_id)
    ),
    irr_shift = data.frame(
      dIr = 1, prec = shifted_climate$prec, `I(prec^2)` = shifted_climate$precsq,
      dday0_14C = shifted_climate$dday0_14C, dday15_31C = shifted_climate$dday15_31C,
      dday32_maxC = shifted_climate$dday32_maxC, Trend = 0, Trend2 = 0, Id = as.factor(county_id)
    )
  )
  
  # Predict moments for each scenario
  moments_list <- list()
  for (scenario in names(scenarios)) {
    newdata <- scenarios[[scenario]]
    mu1 <- predict(model_y1, newdata = newdata)
    mu2 <- predict(model_y2, newdata = newdata)
    mu3 <- predict(model_y3, newdata = newdata)
    moments_list[[scenario]] <- c(mu1, mu2, mu3)
  }
  
  return(moments_list)
}




# Optimize maximum entropy
estimate_maxent_from_moments <- function(mu) {
  safe_integrate <- function(f, lower, upper) {
    result <- tryCatch({
      integrate(f, lower = lower, upper = upper)$value
    }, error = function(e) {
      NA
    })
    return(result)
  }
  
  objective <- function(lambdas) {
    Z <- safe_integrate(function(y) exp(lambdas[1]*y + lambdas[2]*y^2 + lambdas[3]*y^3), lower = -10, upper = 10)
    if (is.na(Z) || !is.finite(Z)) return(1e8)
    
    m1 <- safe_integrate(function(y) y * exp(lambdas[1]*y + lambdas[2]*y^2 + lambdas[3]*y^3) / Z, lower = -10, upper = 10)
    m2 <- safe_integrate(function(y) y^2 * exp(lambdas[1]*y + lambdas[2]*y^2 + lambdas[3]*y^3) / Z, lower = -10, upper = 10)
    m3 <- safe_integrate(function(y) y^3 * exp(lambdas[1]*y + lambdas[2]*y^2 + lambdas[3]*y^3) / Z, lower = -10, upper = 10)
    
    if (any(is.na(c(m1, m2, m3))) || any(!is.finite(c(m1, m2, m3)))) {
      return(1e8)
    }
    
    return(sum((c(m1, m2, m3) - mu)^2))
  }
  
  opt <- optim(c(0, 0, 0), objective, method = "BFGS")
  return(opt$par)
}

generate_maxent_pdf <- function(lambdas) {
  Z <- integrate(function(y) exp(lambdas[1]*y + lambdas[2]*y^2 + lambdas[3]*y^3),
                 lower = -10, upper = 10)$value
  function(y) exp(lambdas[1]*y + lambdas[2]*y^2 + lambdas[3]*y^3) / Z
}


```

## 3. Loop Over All Counties to Estimate MaxEnt PDFs
# Assume models model_y1, model_y2, model_y3 are already fitted

```{r mbme loop and visualize , cache = F, echo = F, results = "hide"}

# Matches the Maximum Entropy distribution estimation stage in Tack's MATLAB scripts (Moments.do -> MaxEnt.m)
# Matches description of max entropy approach, Section 3.2 in Tack (2012)

# Loop over all counties to generate PDFs for four scenarios

county_list <- unique(df_ar$Id)
all_county_pdf_list <- list()

for (cid in county_list) {
  moments_list <- predict_moments_for_county(df_ar, model_y1, model_y2, model_y3, cid)
  
  pdf_list <- list()
  
  for (scenario in names(moments_list)) {
    moments <- moments_list[[scenario]]
    
    if (any(is.na(moments)) || any(!is.finite(moments))) {
      cat("Skipping", scenario, "for county", cid, "due to bad moments\n")
      next
    }
    
    lambda_est <- estimate_maxent_from_moments(moments)
    pdf_func <- generate_maxent_pdf(lambda_est)
    
    pdf_list[[scenario]] <- list(pdf = pdf_func, moments = moments, lambdas = lambda_est)
  }
  
  all_county_pdf_list[[as.character(cid)]] <- pdf_list
}

```{r 4 scenario plot , cache = F, echo = F, results = "hide"}


## 4. Plot Example: Craighead County, 4 Scenarios

pdfs_craighead <- all_county_pdf_list[["5031"]]

curve(pdfs_craighead$irr_base$pdf(x), from = 0, to = 3, col = "blue", lwd = 2,
      ylab = "Density", xlab = "Yield", main = "Craighead County: Irrigated Base")
curve(pdfs_craighead$irr_shift$pdf(x), from = 0, to = 3, col = "red", lwd = 2, add = TRUE)
curve(pdfs_craighead$dry_base$pdf(x), from = 0, to = 3, col = "green", lwd = 2, add = TRUE)
curve(pdfs_craighead$dry_shift$pdf(x), from = 0, to = 3, col = "purple", lwd = 2, add = TRUE)
legend("topright", legend = c("Irrigated Base", "Irrigated Shift", "Dryland Base", "Dryland Shift"),
       col = c("blue", "red", "green", "purple"), lwd = 2)

```

# Create a Partial Moment Calculator

```{r partial moment , cache = F, echo = F, results = "hide"}

# Matches calculation of lower partial moments (first-order) as in Tack (2012)
# Corresponds to partial moment definitions discussed in Section 4 of Tack (2012)

calculate_partial_moment <- function(pdf_func, cutoff, order = 1, lower = -10, upper = 10) {
  # Integrate (cutoff - y)^k * f(y) over y <= cutoff
  
  safe_integrate <- function(f, lower, upper) {
    tryCatch({
      integrate(f, lower = lower, upper = upper)$value
    }, error = function(e) {
      NA
    })
  }
  
  integral <- safe_integrate(
    function(y) ifelse(y <= cutoff, (cutoff - y)^order * pdf_func(y), 0),
    lower = lower,
    upper = upper
  )
  
  return(integral)
}

```


#  Loop Over All Counties × Scenarios

```{r loop all counties x scenarios , cache = F, echo = F, results = "hide"}

#  Matches loop structure in Tack's MaxEnt.m to calculate partial moments for each scenario

partial_moment_results <- list()

for (cid in county_list) {
  pdfs <- all_county_pdf_list[[as.character(cid)]]
  
  if (is.null(pdfs)) next
  
  results_per_county <- list()
  
  for (scenario in names(pdfs)) {
    pdf_func <- pdfs[[scenario]]$pdf
    moments <- pdfs[[scenario]]$moments
    
    # Use predicted mean (mu1) as cutoff
    cutoff <- moments[1]  
    
    pm_value <- calculate_partial_moment(pdf_func, cutoff = cutoff, order = 1)
    
    results_per_county[[scenario]] <- pm_value
  }
  
  partial_moment_results[[as.character(cid)]] <- results_per_county
}



```


#  Organize Into a Table

```{r Organize Into a Table , cache = F, echo = F, results = "hide"}

# Matches Table 5 in Tack (2012)
# Displays the average partial moments under each scenario

partial_moment_table <- do.call(rbind, lapply(names(partial_moment_results), function(cid) {
  entry <- partial_moment_results[[cid]]
  
  if (is.null(entry)) return(NULL)
  
  tibble(
    County = as.integer(cid),
    dry_base = entry$dry_base,
    dry_shift = entry$dry_shift,
    irr_base = entry$irr_base,
    irr_shift = entry$irr_shift
  )
}))

partial_moment_table

```

